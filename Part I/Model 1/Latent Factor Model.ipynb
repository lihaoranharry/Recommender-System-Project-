{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Idea: \n",
    "$R \\approx P \\times Q^T = \\hat{R}$ <br>\n",
    "$K$ is the number of latent factors.  <br>\n",
    "Adding bias in the model, we have $\\hat{r_{ij}} = b+bu_i+bd_j+\\sum_{k=1}^{K}p_{ik}q_{kj}$ <br>\n",
    "$S$ is the set of observed user-item pair <br>\n",
    "Our goal is to minimize $\\sum_{(u_i,d_j,r_{ij})\\in S} (r_{ij}-\\sum_{k=1}^K p_{ik}q_{kj})+\\frac{\\beta}{2}(\\sum_{k=1}^K(\\|P\\|^2+\\|Q\\|^2)$ <br>\n",
    "The optimization is achieved by stochastic gradient descent algorithm <br>\n",
    "encoding: purchased:5, add_to_cart: 1, viewed: 2, missing: 0 <br>\n",
    "Metric: Hit rate <br>\n",
    "Number of recommended items: 50 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseLine():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j]\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(df,proportion):\n",
    "    \"\"\"\n",
    "    This function aims to create cross validation and training set\n",
    "    Proportion controls sample size in later comparison\n",
    "    \"\"\"\n",
    "\n",
    "    user=[]\n",
    "    category=[]\n",
    "    action=[]\n",
    "    random=[]\n",
    "    for person in df.index:\n",
    "        for item in df.columns:\n",
    "            if df.loc[person,item]>0:\n",
    "                user.append(person)\n",
    "                category.append(item)\n",
    "                action.append(df.loc[person,item])\n",
    "                random.append(np.random.rand())\n",
    "    pair = pd.DataFrame({'user':user,'category':category,'action':action,'random_number':random})\n",
    "    test = pair[pair['random_number']>=proportion]\n",
    "    train = pair[pair['random_number']<proportion]\n",
    "    keep = []\n",
    "    for row in test.itertuples():\n",
    "        if row[4] in list(train['user']):\n",
    "            keep.append(row[0])\n",
    "    test = test.loc[keep]\n",
    "    train=df\n",
    "    for row in test.itertuples():\n",
    "        train.loc[row[4],row[2]]=0\n",
    "    return train,test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cross_Validation(train):\n",
    "    \"\"\"\n",
    "        Arguments\n",
    "        - train (dataframe) : training set\n",
    "    \n",
    "    \"\"\"\n",
    "    train.replace(['purchased','add_to_cart','viewed'],[5,2,1],inplace=True)\n",
    "    train.fillna(0,inplace=True)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    tune K, alpha, beta, iterations, number_of_recommendation on set cv\n",
    "    \"\"\"\n",
    "    training_sub,cv = train_test_split(train,0.8)\n",
    "    cv = cv.set_index(['user','category'])\n",
    "    R=training_sub.values\n",
    "    \n",
    "    best_rate = 0\n",
    "    best_model = {'K':0,'beta':0,'iterations':0}\n",
    "    log = []\n",
    "    n_recommended=50\n",
    "    alpha = 0.01\n",
    "    for K in [2,20,50,100,150,200,300]:\n",
    "        for beta in [0.01,0.05,0.1]:\n",
    "            for iterations in [20,50,100,200]:\n",
    "                start = time.time()\n",
    "                print(\"K:{},beta:{},iterations:{}\".format(K,beta,iterations))\n",
    "                mf = MF(R, K=K, alpha=alpha, beta=beta, iterations=iterations)\n",
    "                mf.train()\n",
    "                pred_svd = pd.DataFrame(mf.full_matrix(),index=train.index,columns=train.columns)\n",
    "                rate_svd = 0\n",
    "                precision = 0\n",
    "                for user in pred_svd.index:\n",
    "                    #get predictions for all missing cells in training matrix\n",
    "                    heap_svd=[]\n",
    "                    available = 0 #intercection of prediction & test\n",
    "                    hit = 0 #correctly predict purchase\n",
    "                    for item in pred_svd.columns:\n",
    "                        if training_sub.loc[user,item] <1: \n",
    "                            heapq.heappush(heap_svd,(pred_svd.loc[user,item],item))\n",
    "                    #make recommendation of the first n_recommended items\n",
    "                    for (rate,item) in heapq.nlargest(n_recommended,heap_svd):\n",
    "                        if (user,str(item)) in cv.index:\n",
    "                            available += 1\n",
    "                            if cv.loc[(user,str(item)),'action'] == 5:\n",
    "                                hit += 1\n",
    "                    if available > 0:\n",
    "                        rate_svd += hit/available\n",
    "                        precision += hit/50\n",
    "                print(\"rate_svd is {}\".format(rate_svd))\n",
    "                print(\"precision is {}\".format(precision))\n",
    "                if rate_svd > best_rate:\n",
    "                    best_rate = rate_svd\n",
    "                    best_model['K']=K\n",
    "                    best_model['beta']=beta\n",
    "                    best_model['iterations']=iterations\n",
    "                    \n",
    "                end= time.time()\n",
    "                total = end-start\n",
    "                print(total)\n",
    "                log.append((K,beta,iterations,rate_svd,precision,total))\n",
    "    return log,training_sub,cv,best_model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(best_model,training_sub,test):\n",
    "    \"\"\"\n",
    "    use the best model from cv to do prediction\n",
    "    \"\"\"\n",
    "    rate_svd = 0\n",
    "    rate_base = 0\n",
    "    alpha =0.01\n",
    "    n_recommended=50\n",
    "    R = training_sub.values\n",
    "    test = test.set_index(['user','category'])\n",
    "    if best_model['K']>0:                    \n",
    "        mf = MF(R, K=best_model['K'], alpha=alpha, beta=best_model['beta'], iterations=best_model['iterations'])\n",
    "        mf.train()    \n",
    "        base = BaseLine(R, K=best_model['K'], alpha=alpha, beta=best_model['beta'], iterations=best_model['iterations'])\n",
    "        base.train()\n",
    "        pred_svd = pd.DataFrame(mf.full_matrix(),index=training_sub.index,columns=training_sub.columns)\n",
    "        pred_base = pd.DataFrame(base.full_matrix(),index=training_sub.index,columns=training_sub.columns)\n",
    "\n",
    "        for user in pred_svd.index:\n",
    "            #get predictions for all missing cells in training matrix\n",
    "            heap_svd=[]\n",
    "            heap_base=[]\n",
    "            available_svd = 0\n",
    "            hit_svd = 0\n",
    "            available_base = 0\n",
    "            hit_base = 0\n",
    "            for item in pred_svd.columns:\n",
    "                if training_sub.loc[user,item] <1: \n",
    "                    heapq.heappush(heap_svd,(pred_svd.loc[user,item],item))\n",
    "                    heapq.heappush(heap_base,(pred_base.loc[user,item],item))\n",
    "            #make recommendation of the first n_recommended items\n",
    "            for (rate,item) in heapq.nlargest(n_recommended,heap_svd):\n",
    "                if (user,int(item)) in test.index:\n",
    "                    available_svd += 1\n",
    "                    if test.loc[(user,int(item)),'action'] == 'purchased':\n",
    "                        hit_svd += 1\n",
    "            if available_svd > 0:\n",
    "                rate_svd +=  hit_svd/available_svd\n",
    "\n",
    "            #using baseline model to do recommendation\n",
    "            for (rate,item) in heapq.nlargest(n_recommended,heap_base):\n",
    "                if (user,int(item)) in test.index:\n",
    "                    available_base += 1\n",
    "                    if test.loc[(user,int(item)),'action'] == 'purchased':\n",
    "                        hit_base += 1\n",
    "            if available_base > 0:\n",
    "                rate_base +=  hit_svd/available_base\n",
    "    return rate_base,rate_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (113,128,142,164,186,191,198,213,219,238,252,272,313,331,336,351,356,358,368,379,393,396,441,445,448,449,463,468,470,471,472,480,484,492,495,511,514,524,526,534,539,540,542,544,547,552,556,559,560,563,570,574,575,579,584,587,592,595,600,602,606,609,627,628,629,630,632,635,636,638,640,644,646,651,652,653,671,675,679,680,682,685,687,688,692,695,698,703,710,714,715,717,718,720,721,723,724,725,726,730,736,740,742,744,745,747,750,751,752,753,755,757,759,760,767,771,773,778,780,781,782,784,785,788,790,791,796,805,818,820,823,824,825,826,828,829,834,835,836,837,838,839,842,843,849,850,851,852,853,854,858,861,863,864,865,867,869,871,874,875,876,878,879,888,889,890,892,907,908,912,913,914,915,916,917,918,921,922,924,926,927,928,929,930,931,932,934,935,936,938,939,940,941,943,944,950,951,952,954,956,962,963,966,970,972,974,975,976,978,979,981,982,983,984,985,986,987,996,1001,1002,1003,1004,1007,1008,1009,1011,1012,1014,1017,1021,1024,1026,1027,1028,1036,1039,1042,1043,1045,1049,1052,1057,1059,1060,1061,1062,1063,1064,1065,1067,1068,1070,1074,1078,1084,1088,1091,1096,1098,1100,1101,1103,1106,1108,1109,1112,1115,1118,1119,1120,1122,1132,1133,1136,1140,1142,1148,1149,1151,1157,1159,1165,1166,1167,1168,1170,1171,1173,1177,1180,1181,1182,1183,1184,1185,1187,1188,1189,1190,1192,1195,1196,1198,1199,1200,1201,1202,1203,1204,1205,1207,1208,1212,1213,1214,1215,1216,1217,1219,1220,1221,1222,1225,1227,1229,1232,1236,1241,1243,1245,1246,1247,1248,1251,1252,1253,1254,1259,1262,1263,1264,1265,1266,1270,1272,1276,1285,1286,1287,1289,1293,1294,1296,1297,1299,1300,1301,1303,1308,1309,1310,1311,1313,1317,1322,1323,1324,1326,1327,1328,1335,1336,1340,1347,1349,1352,1356,1364,1369,1370,1372,1376,1377,1378,1379,1380,1381,1384,1385,1387,1390,1394,1395,1396,1397,1398,1400,1402,1411,1417,1428,1429,1430,1435,1441,1446,1447,1449,1451,1452,1454,1458,1460,1462,1463,1464,1465,1466,1467,1471,1472,1473,1476,1477,1478,1479,1480,1481,1482,1489,1497,1504,1513,1514,1516,1517,1519,1520,1521,1523,1526,1527,1529,1532,1534,1539,1540,1542,1549,1550,1559,1561,1564,1565,1569,1573,1584,1589,1595,1596,1597,1600,1602,1604,1605,1606,1608,1611,1612,1615,1617,1618,1619,1620,1623,1626,1627,1629,1633,1636,1639,1650,1651,1653,1654,1656,1657,1662,1664,1670,1675,1676,1677,1679,1680,1681,1682,1683,1684,1687,1688,1689,1691,1692,1693,1694,1695,1696,1697,1698,1699,1701,1702,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1724,1725,1727,1730,1732,1733,1734,1735,1736,1737,1738,1740,1741,1742,1743,1744,1747,1748,1750,1752,1755,1756,1757,1758,1759,1760,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1778,1779,1780,1782,1783,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1807,1808,1809,1813,1814,1815,1816,1817,1818,1819,1821,1822,1823,1824,1825,1826,1827,1829,1830,1831,1832,1833,1834,1835,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (47,59,79,113,128,142,154,164,186,191,198,209,213,219,238,252,265,272,305,313,331,336,351,356,358,368,379,393,396,403,427,437,441,448,449,468,470,471,472,480,484,492,495,511,514,526,534,540,542,544,545,552,559,560,570,574,575,579,584,586,587,592,594,595,600,602,604,606,609,621,628,629,630,635,636,638,640,644,646,651,652,653,659,665,671,674,675,679,680,682,685,687,688,692,695,698,703,709,710,714,715,717,718,720,721,722,723,724,726,730,736,740,741,742,744,745,747,751,752,753,755,757,759,767,770,771,773,778,780,781,782,784,785,788,790,791,805,818,820,822,823,824,825,826,828,829,834,835,836,837,838,839,842,843,849,850,852,853,854,858,861,863,864,867,869,874,875,876,878,885,886,888,889,892,907,908,912,913,914,915,916,917,918,920,924,926,927,928,930,932,934,935,936,939,940,941,942,943,944,950,951,952,954,956,959,962,963,964,970,972,975,978,979,981,982,983,985,988,1000,1001,1002,1003,1004,1005,1007,1008,1009,1011,1012,1014,1015,1017,1021,1024,1026,1027,1028,1032,1034,1036,1037,1039,1042,1043,1045,1049,1052,1057,1059,1060,1061,1062,1063,1064,1067,1068,1070,1071,1074,1078,1082,1084,1088,1089,1091,1092,1096,1097,1098,1100,1101,1103,1108,1109,1112,1114,1115,1118,1119,1120,1122,1126,1132,1133,1136,1140,1142,1148,1149,1151,1157,1159,1163,1165,1166,1167,1168,1170,1171,1173,1177,1180,1181,1182,1184,1185,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1198,1199,1200,1201,1202,1203,1204,1205,1207,1208,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1225,1227,1232,1236,1238,1241,1243,1245,1247,1248,1251,1252,1253,1254,1259,1262,1263,1264,1265,1266,1270,1272,1281,1285,1286,1287,1289,1292,1293,1294,1296,1297,1300,1301,1303,1308,1309,1310,1311,1313,1316,1317,1322,1323,1324,1326,1327,1328,1335,1336,1340,1344,1347,1349,1352,1355,1356,1358,1361,1364,1368,1369,1370,1372,1376,1377,1378,1379,1380,1381,1384,1385,1387,1390,1394,1395,1396,1397,1398,1400,1407,1411,1416,1417,1428,1429,1430,1435,1438,1439,1441,1446,1447,1449,1451,1452,1454,1458,1460,1462,1463,1464,1465,1466,1467,1468,1470,1472,1473,1476,1477,1478,1479,1480,1481,1482,1485,1489,1497,1504,1510,1512,1513,1514,1517,1520,1521,1523,1526,1527,1529,1532,1534,1540,1542,1548,1549,1550,1559,1561,1564,1565,1569,1573,1580,1584,1586,1587,1589,1595,1596,1597,1600,1602,1604,1605,1606,1608,1611,1612,1615,1616,1617,1618,1620,1623,1626,1627,1629,1632,1633,1636,1637,1638,1639,1641,1649,1650,1651,1653,1654,1656,1657,1662,1664,1670,1671,1677,1679,1680,1682,1683,1684,1685,1687,1688,1689,1691,1692,1693,1695,1696,1698,1699,1701,1702,1707,1711,1712,1713,1715,1717,1718,1719,1720,1721,1722,1724,1725,1727,1729,1730,1732,1733,1734,1735,1736,1737,1738,1740,1741,1744,1747,1748,1749,1750,1752,1755,1757,1759,1762,1763,1764,1765,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1778,1779,1780,1783,1786,1787,1788,1790,1791,1792,1793,1794,1795,1796,1797,1799,1800,1801,1802,1803,1804,1807,1808,1809,1812,1814,1815,1816,1818,1819,1821,1822,1823,1824,1825,1826,1827,1828,1830,1831,1832,1833,1834,1835,1838,1839,1843,1844,1845,1846,1847,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1884,1885,1886,1887,1889,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1903,1904,1906,1907,1908,1909,1912,1913,1914,1915,1917,1918,1919,1921,1922,1923,1925,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1940,1941,1943,1944,1945,1946,1947,1948,1949,1951,1952,1953,1954,1955,1956,1957) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"/Users/nihaozheng/Desktop/Personalization/project/retailrocket-recommender-system-dataset/rating matrix.csv\",\n",
    "                   index_col='user')\n",
    "train = pd.read_csv(\"/Users/nihaozheng/Desktop/Personalization/project/retailrocket-recommender-system-dataset/training.csv\",\n",
    "                   index_col='user')\n",
    "test = pd.read_csv(\"/Users/nihaozheng/Desktop/Personalization/project/retailrocket-recommender-system-dataset/testing.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross Validation\n",
    "# WARNING: DO NOT RUN THIS LINE, IT TAKES FIVE HORS FROM YOUR LIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log,training_sub,cv,best_model = Cross_Validation(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result of cross validation\n",
    "best_model = {'K':100, 'beta':0.01, 'iterations':20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data used in cv\n",
    "training_sub = pd.read_csv(\"/Users/nihaozheng/Desktop/Personalization/project/retailrocket-recommender-system-dataset/cv_training.csv\",\n",
    "                          index_col='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 190.6098\n",
      "Iteration: 20 ; error = 127.5772\n",
      "Iteration: 10 ; error = 189.9657\n",
      "Iteration: 20 ; error = 10575.8709\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "rate_based, rate_svd= predict(best_model,training_sub,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
